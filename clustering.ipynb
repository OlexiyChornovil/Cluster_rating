{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "global bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import itertools\n",
    "import matplotlib.style as style\n",
    "import os\n",
    "import operator\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "global aaa\n",
    "\n",
    "def clustering_kmeans(df, n, count_offset):\n",
    "    global aaa\n",
    "    aaa = df\n",
    "    \n",
    "    clustering = KMeans(n_clusters=n).fit(df)\n",
    "    for i in range(0, len(clustering.labels_)):\n",
    "        if clustering.labels_[i] > -1:\n",
    "            clustering.labels_[i] += count_offset\n",
    "    count_offset = np.max(clustering.labels_) + 1\n",
    "    labels_df = pd.DataFrame({'cluster': clustering.labels_}, df.index)\n",
    "    return df.join(labels_df) , count_offset\n",
    "\n",
    "def df_separate_on_column(df, column_name):\n",
    "    #returns list of dfs with same value in said column\n",
    "    lst = []\n",
    "    for item in list(df[column_name].unique()):\n",
    "        lst.append(df[df[column_name] == item])\n",
    "    return lst\n",
    "\n",
    "def df_drop_col(df, col_names):\n",
    "    if isinstance(col_names, list):\n",
    "        for item in col_names:\n",
    "            if item in list(df.columns):\n",
    "                df = df.drop(item, axis=1)\n",
    "        return df\n",
    "    else:\n",
    "        if col_names in list(df.columns):\n",
    "            df = df.drop(col_names, axis=1)\n",
    "        return df\n",
    "    \n",
    "def dfs_join(df1, df2, col_names_to_drop=None):\n",
    "    df1 = df_drop_col(df1, col_names_to_drop)\n",
    "    df2 = df_drop_col(df2, col_names_to_drop)\n",
    "    return df1.append(df2)\n",
    "\n",
    "def keep_columns(df, col_names):\n",
    "    drop = list(set(list(df)) - set(col_names))\n",
    "    return df.drop(drop, axis = 1)\n",
    "\n",
    "def find_same_rows_by_value(df1, df2, col_names_to_keep):\n",
    "    df1_n = keep_columns(df1, col_names_to_keep)\n",
    "    df2_n = keep_columns(df2, col_names_to_keep)\n",
    "    return df1_n.merge(df2_n)\n",
    "\n",
    "def rate_by_amount(df_from_prev_gen, df, cols_intersected):\n",
    "    scores = []\n",
    "    for cluster in df_separate_on_column(df, \"cluster\"):\n",
    "        score = len(find_same_rows_by_value(df_from_prev_gen, cluster, cols_intersected))/len(df_from_prev_gen)\n",
    "        scores.append((score, df_from_prev_gen, cluster))\n",
    "    return scores\n",
    "\n",
    "def select_best_rating(ratings_list):\n",
    "    if len(ratings_list) == 0:\n",
    "        return None\n",
    "    return max(ratings_list,key=operator.itemgetter(0))\n",
    "\n",
    "def merge_clusters_completely(df_prev_gen, df_new, merge_labels):\n",
    "    df = df_prev_gen.merge(df_new, on=merge_labels, how=\"outer\")\n",
    "    label = df[\"cluster_y\"].unique()[0]\n",
    "    df = df.drop(\"cluster_x\", axis=1).drop(\"cluster_y\", axis=1)\n",
    "    df[\"cluster\"] = label\n",
    "    return df\n",
    "\n",
    "def remove_df_from_list(lst, df):\n",
    "    for i in range(len(lst)):\n",
    "        if df.equals(lst[i]):\n",
    "            del lst[i]\n",
    "            return\n",
    "    print(\"no same element found\")\n",
    "\n",
    "def remove_rows_contained_in_df(df, df_to_remove, column_to_ignore):\n",
    "    return pd.concat([df, df_to_remove.drop(column_to_ignore, axis=1), \n",
    "               df_to_remove.drop(column_to_ignore, axis=1)]).drop_duplicates(keep=False)\n",
    "\n",
    "def rebase_column_in_df_list(list_df, col_name):\n",
    "    for i in range(len(list_df)):\n",
    "        list_df[i][col_name] = i\n",
    "    df = pd.concat(list_df)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def dtw_rating(df_from_prev_gen, df, cols_intersected):\n",
    "    # https://cs.stackexchange.com/questions/53250/normalized-measure-from-dynamic-time-warping\n",
    "    # problem with negative results on dtw\n",
    "    df1 = df_from_prev_gen[cols_intersected].to_numpy()\n",
    "    df2 = df[cols_intersected].to_numpy()\n",
    "    dist, path = fastdtw(df1, df2)\n",
    "    \n",
    "    m1 = len(df1)*np.amax(df1)\n",
    "    m2 = len(df2)*np.amax(df2)\n",
    "    m = max(m1, m2)\n",
    "    \n",
    "    rating = (m-dist)/m\n",
    "    return rating\n",
    "\n",
    "def rate_by_dtw(df_from_prev_gen, df, cols_intersected):\n",
    "    scores = []\n",
    "    for cluster in df_separate_on_column(df, \"cluster\"):\n",
    "        score = dtw_rating(df_from_prev_gen, cluster, cols_intersected)\n",
    "        #print(score)\n",
    "        scores.append((score, df_from_prev_gen, cluster))\n",
    "    return scores\n",
    "\n",
    "def kmeans(data, n, score, clustering_method, rating_strat, merge_strat):\n",
    "    to_do = pd.DataFrame()\n",
    "    running = []\n",
    "    run_in_next_iter = []\n",
    "    finished = []\n",
    "    first_time = True\n",
    "    count_offset = 0\n",
    "    persistent_labels = list(data.columns)\n",
    "    for timestamp_data in df_separate_on_column(data, \"time\"):\n",
    "        if first_time:\n",
    "            first_time = False\n",
    "            results, count_offset = clustering_method(timestamp_data, n, count_offset)\n",
    "            running.append(df_separate_on_column(results, \"cluster\"))\n",
    "            running = [item for sublist in running for item in sublist]\n",
    "        \n",
    "        else:\n",
    "            still_running = True\n",
    "            while still_running:\n",
    "                ratings = []\n",
    "                for current in running:\n",
    "                    tmp = dfs_join(timestamp_data, current, [\"cluster\"])\n",
    "                    results, count_offset = clustering_method(tmp, n, count_offset)\n",
    "                    ratings.append(rating_strat(current, results, persistent_labels))\n",
    "                ratings = [item for sublist in ratings for item in sublist] #flatten list\n",
    "                best = select_best_rating(ratings)\n",
    "                \n",
    "                if (best is not None) and (best[0] >= score):\n",
    "                        run_in_next_iter.append(merge_strat(best[1], best[2], persistent_labels))\n",
    "                        remove_df_from_list(running, best[1])\n",
    "                        timestamp_data = remove_rows_contained_in_df(timestamp_data, best[2], \"cluster\")\n",
    "                else:\n",
    "                    if timestamp_data.empty:\n",
    "                        continue\n",
    "                    results, count_offset = clustering_method(timestamp_data, n, count_offset)\n",
    "                    \n",
    "                    finished.append(running)\n",
    "                    running = run_in_next_iter\n",
    "                    for item in df_separate_on_column(results, \"cluster\"):\n",
    "                        running.append(item)\n",
    "                    run_in_next_iter = []\n",
    "                    still_running = False\n",
    "    finished.append(running)\n",
    "    final_result = [item for sublist in finished for item in sublist] #flatten list\n",
    "    return rebase_column_in_df_list(final_result, \"cluster\")                \n",
    "\n",
    "def return_clustering_1(data, n, score):\n",
    "    return kmeans(data, n, score, clustering_kmeans, rate_by_amount, merge_clusters_completely)\n",
    "\n",
    "def return_clustering_2(data, n, score):\n",
    "    return kmeans(data, n, score, clustering_kmeans, rate_by_dtw, merge_clusters_completely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_colwidth', -1)  \n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "t_data = pd.read_pickle(\"t_data.pickle\")\n",
    "c_data = pd.read_pickle(\"c_data.pickle\")\n",
    "\n",
    "a = t_data[t_data[\"time\"]==2]\n",
    "b = t_data[t_data[\"object_id\"]==10]\n",
    "c = c_data[c_data[\"object_id\"] == 20]\n",
    "d = c_data[c_data[\"time\"]==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-545af4dcfd39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#fin = kmeans(t_data, 5, 0.8, clustering_kmeans, rate_by_dtw, merge_clusters_completely)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_clustering_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-c2adf5fba27b>\u001b[0m in \u001b[0;36mreturn_clustering_1\u001b[0;34m(data, n, score)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreturn_clustering_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclustering_kmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate_by_amount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_clusters_completely\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreturn_clustering_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-c2adf5fba27b>\u001b[0m in \u001b[0;36mkmeans\u001b[0;34m(data, n, score, clustering_method, rating_strat, merge_strat)\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0;32mglobal\u001b[0m \u001b[0mbbb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0mbbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestamp_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclustering_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mfinished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-c2adf5fba27b>\u001b[0m in \u001b[0;36mclustering_kmeans\u001b[0;34m(df, n, count_offset)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0maaa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mclustering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/.local/lib/python3.6/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"C\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],\n\u001b[0;32m--> 859\u001b[0;31m                         order=order, copy=self.copy_x)\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    584\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[0;32m--> 586\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "#fin = kmeans(t_data, 5, 0.8, clustering_kmeans, rate_by_amount, merge_clusters_completely)\n",
    "#fin = kmeans(t_data, 5, 0.8, clustering_kmeans, rate_by_dtw, merge_clusters_completely)\n",
    "\n",
    "fin = return_clustering_1(t_data, 1, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>time</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [object_id, time, feature1, feature2]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>time</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [object_id, time, feature1, feature2]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbb.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
